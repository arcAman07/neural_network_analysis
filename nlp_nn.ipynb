{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory stats before clearing:\n",
      "GPU Memory Stats:\n",
      "MPS memory allocated: 0.00 GB\n",
      "MPS memory cached: 17.56 GB\n",
      "\n",
      "System Memory Stats:\n",
      "Total: 17.18 GB\n",
      "Available: 2.90 GB\n",
      "Used: 5.78 GB\n",
      "Percentage: 83.1%\n",
      "\n",
      "Clearing memory...\n",
      "\n",
      "Memory stats after clearing:\n",
      "GPU Memory Stats:\n",
      "MPS memory allocated: 0.00 GB\n",
      "MPS memory cached: 0.14 GB\n",
      "\n",
      "System Memory Stats:\n",
      "Total: 17.18 GB\n",
      "Available: 7.71 GB\n",
      "Used: 6.00 GB\n",
      "Percentage: 55.1%\n",
      "\n",
      "If you're still seeing high memory usage, consider restarting your Python environment.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "import psutil\n",
    "\n",
    "def clear_memory():\n",
    "    # Clear CUDA cache if available\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        torch.cuda.reset_accumulated_memory_stats()\n",
    "\n",
    "    # Clear MPS cache if available\n",
    "    if hasattr(torch.mps, 'empty_cache'):\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "    # Run garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "def print_memory_stats():\n",
    "    print(\"GPU Memory Stats:\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA memory allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "        print(f\"CUDA memory cached: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "    elif hasattr(torch.mps, 'current_allocated_memory'):\n",
    "        print(f\"MPS memory allocated: {torch.mps.current_allocated_memory() / 1e9:.2f} GB\")\n",
    "        print(f\"MPS memory cached: {torch.mps.driver_allocated_memory() / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(\"No GPU available\")\n",
    "\n",
    "    print(\"\\nSystem Memory Stats:\")\n",
    "    vm = psutil.virtual_memory()\n",
    "    print(f\"Total: {vm.total / 1e9:.2f} GB\")\n",
    "    print(f\"Available: {vm.available / 1e9:.2f} GB\")\n",
    "    print(f\"Used: {vm.used / 1e9:.2f} GB\")\n",
    "    print(f\"Percentage: {vm.percent}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Memory stats before clearing:\")\n",
    "    print_memory_stats()\n",
    "\n",
    "    print(\"\\nClearing memory...\")\n",
    "    clear_memory()\n",
    "\n",
    "    print(\"\\nMemory stats after clearing:\")\n",
    "    print_memory_stats()\n",
    "\n",
    "    print(\"\\nIf you're still seeing high memory usage, consider restarting your Python environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MPS memory efficiency options\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'  # Disable upper limit for memory allocations\n",
    "torch.mps.set_per_process_memory_fraction(0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n"
     ]
    }
   ],
   "source": [
    "# Check for MPS (Metal Performance Shaders) availability\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_memory_usage():\n",
    "    if hasattr(torch.mps, 'current_allocated_memory'):\n",
    "        print(f\"MPS memory allocated: {torch.mps.current_allocated_memory() / 1e9:.2f} GB\")\n",
    "        print(f\"MPS memory cached: {torch.mps.driver_allocated_memory() / 1e9:.2f} GB\")\n",
    "    print(f\"System memory used: {psutil.virtual_memory().percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generation\n",
    "\n",
    "def generate_network():\n",
    "    layers = []\n",
    "    input_shape = [random.randint(1, 256) for _ in range(random.randint(1, 3))]\n",
    "    current_shape = input_shape.copy()\n",
    "\n",
    "    for _ in range(random.randint(1, 5)):\n",
    "        layer_type = random.choice(['Linear', 'Conv1d'])\n",
    "        if layer_type == 'Linear':\n",
    "            in_features = current_shape[-1]\n",
    "            out_features = random.randint(1, 256)\n",
    "            layers.append(f\"nn.Linear(in_features={in_features}, out_features={out_features})\")\n",
    "            current_shape = current_shape[:-1] + [out_features]\n",
    "        elif layer_type == 'Conv1d':\n",
    "            in_channels = current_shape[0]\n",
    "            out_channels = random.randint(1, 64)\n",
    "            kernel_size = random.randint(1, 5)\n",
    "            layers.append(f\"nn.Conv1d(in_channels={in_channels}, out_channels={out_channels}, kernel_size={kernel_size})\")\n",
    "            current_shape[0] = out_channels\n",
    "\n",
    "    return input_shape, current_shape, layers\n",
    "\n",
    "def generate_description(input_shape, output_shape):\n",
    "    return f\"This neural network takes an input of shape {input_shape} and produces an output of shape {output_shape}.\"\n",
    "\n",
    "def generate_data(num_samples, time_limit):\n",
    "    data = []\n",
    "    start_time = time.time()\n",
    "    for _ in tqdm(range(num_samples), desc=\"Generating data\"):\n",
    "        if time.time() - start_time > time_limit:\n",
    "            break\n",
    "        input_shape, output_shape, layers = generate_network()\n",
    "        network = \"nn.Sequential(\\n    \" + \",\\n    \".join(layers) + \"\\n)\"\n",
    "        description = generate_description(input_shape, output_shape)\n",
    "        data.append({\"network\": network, \"description\": description})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis and Visualization\n",
    "\n",
    "def analyze_data(data):\n",
    "    layer_types = []\n",
    "    input_shapes = []\n",
    "    output_shapes = []\n",
    "\n",
    "    for item in data:\n",
    "        network = item['network']\n",
    "        layer_types.extend(re.findall(r'nn\\.(\\w+)', network))\n",
    "        input_shape, output_shape = extract_shapes(item['description'])\n",
    "        input_shapes.append(eval(input_shape))\n",
    "        output_shapes.append(eval(output_shape))\n",
    "\n",
    "    return layer_types, input_shapes, output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(layer_types, input_shapes, output_shapes):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.countplot(y=layer_types)\n",
    "    plt.title('Distribution of Layer Types')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('layer_types_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "    input_dims = [len(shape) for shape in input_shapes]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(input_dims, bins=range(1, max(input_dims)+2), kde=True)\n",
    "    plt.title('Distribution of Input Shape Dimensions')\n",
    "    plt.xlabel('Number of Dimensions')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('input_shape_dimensions.png')\n",
    "    plt.close()\n",
    "\n",
    "    output_dims = [len(shape) for shape in output_shapes]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(output_dims, bins=range(1, max(output_dims)+2), kde=True)\n",
    "    plt.title('Distribution of Output Shape Dimensions')\n",
    "    plt.xlabel('Number of Dimensions')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output_shape_dimensions.png')\n",
    "    plt.close()\n",
    "\n",
    "    input_sizes = [np.prod(shape) for shape in input_shapes]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(input_sizes, bins=30, kde=True)\n",
    "    plt.title('Distribution of Input Sizes')\n",
    "    plt.xlabel('Input Size (Total Number of Elements)')\n",
    "    plt.xscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('input_sizes_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "    output_sizes = [np.prod(shape) for shape in output_shapes]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(output_sizes, bins=30, kde=True)\n",
    "    plt.title('Distribution of Output Sizes')\n",
    "    plt.xlabel('Output Size (Total Number of Elements)')\n",
    "    plt.xscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output_sizes_distribution.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and Dataset\n",
    "\n",
    "class NeuralNetworkDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        input_encoding = self.tokenizer.encode_plus(\n",
    "            item['network'],\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        target_encoding = self.tokenizer.encode_plus(\n",
    "            item['description'],\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_encoding['input_ids'].flatten(),\n",
    "            'attention_mask': input_encoding['attention_mask'].flatten(),\n",
    "            'labels': target_encoding['input_ids'].flatten()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Evaluation\n",
    "\n",
    "def train(model, train_dataloader, optimizer, device, max_time, accumulation_steps=4):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    for i, batch in enumerate(tqdm(train_dataloader, desc=\"Training\")):\n",
    "        if time.time() - start_time > max_time:\n",
    "            break\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Normalize loss to account for accumulation\n",
    "        loss = loss / accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    return total_loss / len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, eval_dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_description_for_network(model, tokenizer, network_str, device):\n",
    "    input_ids = tokenizer.encode(network_str, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids, max_length=100)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "def extract_shapes(description):\n",
    "    shapes = re.findall(r'\\[.*?\\]', description)\n",
    "    return shapes[0] if shapes else None, shapes[-1] if shapes else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, test_data, device):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(test_data, desc=\"Evaluating\"):\n",
    "            input_text = item['network']\n",
    "            true_description = item['description']\n",
    "            \n",
    "            input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "            output = model.generate(input_ids, max_length=100)\n",
    "            predicted_description = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "            \n",
    "            true_input, true_output = extract_shapes(true_description)\n",
    "            pred_input, pred_output = extract_shapes(predicted_description)\n",
    "            \n",
    "            true_labels.append((true_input, true_output))\n",
    "            predicted_labels.append((pred_input, pred_output))\n",
    "\n",
    "    return true_labels, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    correct_input = sum(t[0] == p[0] for t, p in zip(true_labels, predicted_labels))\n",
    "    correct_output = sum(t[1] == p[1] for t, p in zip(true_labels, predicted_labels))\n",
    "    correct_both = sum(t == p for t, p in zip(true_labels, predicted_labels))\n",
    "    \n",
    "    total = len(true_labels)\n",
    "    \n",
    "    accuracy = correct_both / total\n",
    "    \n",
    "    # Convert to binary classification for F1 score\n",
    "    y_true = [1 if t == p else 0 for t, p in zip(true_labels, predicted_labels)]\n",
    "    y_pred = [1 if t == p else 0 for t, p in zip(true_labels, predicted_labels)]\n",
    "    \n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'F1 Score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) device\n",
      "Generating data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data: 100%|██████████| 50000/50000 [00:00<00:00, 175204.91it/s]\n",
      "Generating data: 100%|██████████| 5000/5000 [00:00<00:00, 176541.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 50000 training samples and 5000 evaluation samples.\n",
      "Data generation completed and saved.\n",
      "Analyzing and visualizing data...\n",
      "Preparing model and datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [19:09<00:00,  2.72it/s]\n",
      "Evaluating: 100%|██████████| 1250/1250 [00:46<00:00, 27.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5416\n",
      "Eval loss: 0.0619\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [18:59<00:00,  2.74it/s]\n",
      "Evaluating: 100%|██████████| 1250/1250 [00:49<00:00, 25.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0704\n",
      "Eval loss: 0.0511\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [21:45<00:00,  2.39it/s]   \n",
      "Evaluating: 100%|██████████| 1250/1250 [00:38<00:00, 32.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0592\n",
      "Eval loss: 0.0466\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [17:26<00:00,  2.99it/s]\n",
      "Evaluating: 100%|██████████| 1250/1250 [00:37<00:00, 33.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0534\n",
      "Eval loss: 0.0439\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3125/3125 [17:16<00:00,  3.01it/s]\n",
      "Evaluating: 100%|██████████| 1250/1250 [00:36<00:00, 34.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0497\n",
      "Eval loss: 0.0421\n",
      "Training completed and model saved.\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/5000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb#X15sZmlsZQ%3D%3D?line=191'>192</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m3D Constrained Neural Network Description Generator process completed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb#X15sZmlsZQ%3D%3D?line=193'>194</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb#X15sZmlsZQ%3D%3D?line=194'>195</a>\u001b[0m     main()\n",
      "\u001b[1;32m/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb Cell 15\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb#X15sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39m# Model Evaluation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb#X15sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEvaluating the model...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb#X15sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m true_labels, predicted_labels \u001b[39m=\u001b[39m evaluate_model(model, tokenizer, eval_data, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb#X15sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39m# Calculate and display metrics\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb#X15sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m metrics \u001b[39m=\u001b[39m calculate_metrics(true_labels, predicted_labels)\n",
      "\u001b[1;32m/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m true_description \u001b[39m=\u001b[39m item[\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m input_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(input_text, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(input_ids, max_length\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m predicted_description \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mdecode(output[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn_dim.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m true_input, true_output \u001b[39m=\u001b[39m extract_shapes(true_description)\n",
      "File \u001b[0;32m~/anaconda3/envs/cv2/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cv2/lib/python3.12/site-packages/transformers/generation/utils.py:1696\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1690\u001b[0m     model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_attention_mask_for_generation(\n\u001b[1;32m   1691\u001b[0m         inputs_tensor, generation_config\u001b[39m.\u001b[39mpad_token_id, generation_config\u001b[39m.\u001b[39meos_token_id\n\u001b[1;32m   1692\u001b[0m     )\n\u001b[1;32m   1694\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mencoder_outputs\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1695\u001b[0m     \u001b[39m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1696\u001b[0m     model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_encoder_decoder_kwargs_for_generation(\n\u001b[1;32m   1697\u001b[0m         inputs_tensor, model_kwargs, model_input_name, generation_config\n\u001b[1;32m   1698\u001b[0m     )\n\u001b[1;32m   1700\u001b[0m \u001b[39m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1701\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[0;32m~/anaconda3/envs/cv2/lib/python3.12/site-packages/transformers/generation/utils.py:539\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[0m\n\u001b[1;32m    537\u001b[0m encoder_kwargs[\u001b[39m\"\u001b[39m\u001b[39mreturn_dict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    538\u001b[0m encoder_kwargs[model_input_name] \u001b[39m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 539\u001b[0m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mencoder_outputs\u001b[39m\u001b[39m\"\u001b[39m]: ModelOutput \u001b[39m=\u001b[39m encoder(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mencoder_kwargs)\n\u001b[1;32m    541\u001b[0m \u001b[39mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/cv2/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cv2/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cv2/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1012\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to initialize the model with valid token embeddings\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1012\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_tokens(input_ids)\n\u001b[1;32m   1014\u001b[0m batch_size, seq_length \u001b[39m=\u001b[39m input_shape\n\u001b[1;32m   1016\u001b[0m \u001b[39m# required mask seq length can be calculated via length of past\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cv2/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cv2/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cv2/lib/python3.12/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    164\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    165\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/anaconda3/envs/cv2/lib/python3.12/site-packages/torch/nn/functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2264\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "def main():\n",
    "    # Check for MPS (Metal Performance Shaders) availability\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"Using MPS (Metal Performance Shaders) device\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using CUDA device\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU device\")\n",
    "        print(\"Starting the 3D Constrained Neural Network Description Generator...\")\n",
    "    \n",
    "    # Data Generation\n",
    "    print(\"Generating data...\")\n",
    "    train_data = generate_data(50000, 7200)  # 2 hours = 7200 seconds\n",
    "    eval_data = generate_data(5000, 600)  # 10 minutes for eval data\n",
    "\n",
    "    print(f\"Generated {len(train_data)} training samples and {len(eval_data)} evaluation samples.\")\n",
    "\n",
    "    # Save data to files\n",
    "    with open('train_data.json', 'w') as f:\n",
    "        json.dump(train_data, f)\n",
    "    with open('eval_data.json', 'w') as f:\n",
    "        json.dump(eval_data, f)\n",
    "\n",
    "    print(\"Data generation completed and saved.\")\n",
    "\n",
    "    # Data Analysis and Visualization\n",
    "    print(\"Analyzing and visualizing data...\")\n",
    "    layer_types, input_shapes, output_shapes = analyze_data(train_data)\n",
    "    visualize_data(layer_types, input_shapes, output_shapes)\n",
    "\n",
    "    # Model Training\n",
    "    print(\"Preparing model and datasets...\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "    train_dataset = NeuralNetworkDataset(train_data, tokenizer, max_length=128)\n",
    "    eval_dataset = NeuralNetworkDataset(eval_data, tokenizer, max_length=128)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    eval_dataloader = DataLoader(eval_dataset, batch_size=4)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "    num_epochs = 5\n",
    "    max_train_time = 7200  # 2 hours\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        train_loss = train(model, train_dataloader, optimizer, device, max_train_time - (time.time() - start_time))\n",
    "        eval_loss = evaluate(model, eval_dataloader, device)\n",
    "        print(f\"Train loss: {train_loss:.4f}\")\n",
    "        print(f\"Eval loss: {eval_loss:.4f}\")\n",
    "        # Save checkpoint after each epoch\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'eval_loss': eval_loss,\n",
    "        }, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "        \n",
    "        if time.time() - start_time > max_train_time:\n",
    "            print(\"Training time limit reached. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    # Save the model\n",
    "    model.save_pretrained(\"neural_network_description_model\")\n",
    "    tokenizer.save_pretrained(\"neural_network_description_model\")\n",
    "\n",
    "    print(\"Training completed and model saved.\")\n",
    "    # Model Evaluation\n",
    "    print(\"Evaluating the model...\")\n",
    "    true_labels, predicted_labels = evaluate_model(model, tokenizer, eval_data, device)\n",
    "\n",
    "    # Calculate and display metrics\n",
    "    metrics = calculate_metrics(true_labels, predicted_labels)\n",
    "    print(\"\\nModel Performance Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    # Evaluation on 5 different unique neural network architectures\n",
    "    print(\"\\nEvaluating on 5 different unique neural network architectures...\")\n",
    "    \n",
    "    test_networks = [\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=10)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Linear(in_features=100, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=1)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Linear(in_features=784, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=10)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=1)\n",
    "        )\"\"\"\n",
    "    ]\n",
    "    true_shapes = [\n",
    "        ([3, 100], [10]),\n",
    "        ([100], [1]),\n",
    "        ([1, 100], [10]),\n",
    "        ([784], [10]),\n",
    "        ([1, 100], [1])\n",
    "    ]\n",
    "\n",
    "    test_true_labels = []\n",
    "    test_predicted_labels = []\n",
    "\n",
    "    for i, network in enumerate(test_networks):\n",
    "        print(f\"\\nTesting network {i+1}:\")\n",
    "        print(network)\n",
    "        generated_description = generate_description_for_network(model, tokenizer, network, device)\n",
    "        print(\"Generated description:\", generated_description)\n",
    "        pred_input, pred_output = extract_shapes(generated_description)\n",
    "        print(f\"Predicted shapes: Input {pred_input}, Output {pred_output}\")\n",
    "        print(f\"True shapes: Input {true_shapes[i][0]}, Output {true_shapes[i][1]}\")\n",
    "        \n",
    "        test_true_labels.append((str(true_shapes[i][0]), str(true_shapes[i][1])))\n",
    "        test_predicted_labels.append((pred_input, pred_output))\n",
    "\n",
    "    # Calculate metrics for the 5 test networks\n",
    "    test_metrics = calculate_metrics(test_true_labels, test_predicted_labels)\n",
    "    print(\"\\nTest Network Performance Metrics:\")\n",
    "    for metric, value in test_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    # Detailed analysis of test results\n",
    "    print(\"\\nDetailed analysis of test results:\")\n",
    "    for i, (true, pred) in enumerate(zip(test_true_labels, test_predicted_labels)):\n",
    "        print(f\"\\nNetwork {i+1}:\")\n",
    "        print(f\"True: Input {true[0]}, Output {true[1]}\")\n",
    "        print(f\"Predicted: Input {pred[0]}, Output {pred[1]}\")\n",
    "        print(f\"Input shape correct: {true[0] == pred[0]}\")\n",
    "        print(f\"Output shape correct: {true[1] == pred[1]}\")\n",
    "        print(f\"Both shapes correct: {true == pred}\")\n",
    "\n",
    "    # Additional Analysis\n",
    "    print(\"\\nAdditional Analysis:\")\n",
    "     # Distribution of correct predictions\n",
    "    correct_predictions = sum(t == p for t, p in zip(test_true_labels, test_predicted_labels))\n",
    "    print(f\"Correct predictions: {correct_predictions} out of {len(test_true_labels)}\")\n",
    "    \n",
    "    # Analysis of input shape predictions\n",
    "    input_shape_correct = sum(t[0] == p[0] for t, p in zip(test_true_labels, test_predicted_labels))\n",
    "    print(f\"Correct input shape predictions: {input_shape_correct} out of {len(test_true_labels)}\")\n",
    "    \n",
    "    # Analysis of output shape predictions\n",
    "    output_shape_correct = sum(t[1] == p[1] for t, p in zip(test_true_labels, test_predicted_labels))\n",
    "    print(f\"Correct output shape predictions: {output_shape_correct} out of {len(test_true_labels)}\")\n",
    "    \n",
    "    # Error analysis\n",
    "    errors = [(i, t, p) for i, (t, p) in enumerate(zip(test_true_labels, test_predicted_labels)) if t != p]\n",
    "    if errors:\n",
    "        print(\"\\nError Analysis:\")\n",
    "        for i, true, pred in errors:\n",
    "            print(f\"Network {i+1}:\")\n",
    "            print(f\"  True: Input {true[0]}, Output {true[1]}\")\n",
    "            print(f\"  Predicted: Input {pred[0]}, Output {pred[1]}\")\n",
    "    else:\n",
    "        print(\"\\nNo errors in test set predictions.\")\n",
    "\n",
    "    print(\"\\n3D Constrained Neural Network Description Generator process completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_model(checkpoint_path, device):\n",
    "    \"\"\"\n",
    "    Load a saved T5 model from a checkpoint.\n",
    "    \n",
    "    Args:\n",
    "    checkpoint_path (str): Path to the saved checkpoint file.\n",
    "    device (torch.device): The device to load the model onto.\n",
    "    \n",
    "    Returns:\n",
    "    model (T5ForConditionalGeneration): The loaded model.\n",
    "    tokenizer (T5Tokenizer): The tokenizer associated with the model.\n",
    "    optimizer (torch.optim.Optimizer): The optimizer (if saved in the checkpoint).\n",
    "    start_epoch (int): The epoch to resume training from.\n",
    "    \"\"\"\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    # Initialize the model and tokenizer\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    \n",
    "    # Load the model state dict\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Initialize the optimizer (AdamW in this case, but adjust if you used a different optimizer)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    \n",
    "    # Load the optimizer state dict if it exists in the checkpoint\n",
    "    if 'optimizer_state_dict' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    # Get the epoch number to resume training\n",
    "    start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "    \n",
    "    print(f\"Loaded model from epoch {start_epoch - 1}\")\n",
    "    print(f\"Train loss at save point: {checkpoint.get('train_loss', 'N/A')}\")\n",
    "    \n",
    "    return model, tokenizer, optimizer, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from epoch 4\n",
      "Train loss at save point: 0.049687410358786585\n",
      "Model loaded successfully and moved to mps\n",
      "Ready to resume training from epoch 5\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "checkpoint_path = \"checkpoint_epoch_5.pth\"  # Adjust this to your checkpoint file path\n",
    "model, tokenizer, optimizer, start_epoch = load_saved_model(checkpoint_path, device) \n",
    "print(f\"Model loaded successfully and moved to {device}\")\n",
    "print(f\"Ready to resume training from epoch {start_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data: 100%|██████████| 5000/5000 [00:00<00:00, 158579.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed and model saved.\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5000/5000 [46:12<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy: 0.4496\n",
      "F1 Score: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "eval_data = generate_data(5000, 600)  # 10 minutes for eval data\n",
    "print(\"Training completed and model saved.\")\n",
    "    # Model Evaluation\n",
    "print(\"Evaluating the model...\")\n",
    "true_labels, predicted_labels = evaluate_model(model, tokenizer, eval_data, device)\n",
    "\n",
    "# Calculate and display metrics\n",
    "metrics = calculate_metrics(true_labels, predicted_labels)\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on 5 different unique neural network architectures...\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on 5 different unique neural network architectures\n",
    "print(\"\\nEvaluating on 5 different unique neural network architectures...\")\n",
    "    \n",
    "test_networks = [\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=10)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Linear(in_features=100, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=1)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=10)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Linear(in_features=784, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=10)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=1)\n",
    "        )\"\"\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing network 1:\n",
      "nn.Sequential(\n",
      "            nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3),\n",
      "            nn.ReLU(),\n",
      "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3),\n",
      "            nn.ReLU(),\n",
      "            nn.Linear(in_features=128, out_features=10)\n",
      "        )\n",
      "Generated description: This neural network takes an input of shape [3, 125, 128] and produces an output of shape [128, 125, 10].\n",
      "Predicted shapes: Input [3, 125, 128], Output [128, 125, 10]\n",
      "True shapes: Input [3, 100], Output [10]\n",
      "\n",
      "Testing network 2:\n",
      "nn.Sequential(\n",
      "            nn.Linear(in_features=100, out_features=256),\n",
      "            nn.ReLU(),\n",
      "            nn.Linear(in_features=256, out_features=64),\n",
      "            nn.ReLU(),\n",
      "            nn.Linear(in_features=64, out_features=1)\n",
      "        )\n",
      "Generated description: This neural network takes an input of shape [100] and produces an output of shape [1].\n",
      "Predicted shapes: Input [100], Output [1]\n",
      "True shapes: Input [100], Output [1]\n",
      "\n",
      "Testing network 3:\n",
      "nn.Sequential(\n",
      "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5),\n",
      "            nn.ReLU(),\n",
      "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5),\n",
      "            nn.ReLU(),\n",
      "            nn.Linear(in_features=64, out_features=10)\n",
      "        )\n",
      "Generated description: This neural network takes an input of shape [1, 62, 64] and produces an output of shape [64, 62, 10].\n",
      "Predicted shapes: Input [1, 62, 64], Output [64, 62, 10]\n",
      "True shapes: Input [1, 100], Output [10]\n",
      "\n",
      "Testing network 4:\n",
      "nn.Sequential(\n",
      "            nn.Linear(in_features=784, out_features=512),\n",
      "            nn.ReLU(),\n",
      "            nn.Linear(in_features=512, out_features=256),\n",
      "            nn.ReLU(),\n",
      "            nn.Linear(in_features=256, out_features=10)\n",
      "        )\n",
      "Generated description: This neural network takes an input of shape [784] and produces an output of shape [10].\n",
      "Predicted shapes: Input [784], Output [10]\n",
      "True shapes: Input [784], Output [10]\n",
      "\n",
      "Testing network 5:\n",
      "nn.Sequential(\n",
      "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3),\n",
      "            nn.ReLU(),\n",
      "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3),\n",
      "            nn.ReLU(),\n",
      "            nn.Linear(in_features=64, out_features=1)\n",
      "        )\n",
      "Generated description: This neural network takes an input of shape [1, 62, 64] and produces an output of shape [64, 62, 1].\n",
      "Predicted shapes: Input [1, 62, 64], Output [64, 62, 1]\n",
      "True shapes: Input [1, 100], Output [1]\n"
     ]
    }
   ],
   "source": [
    "true_shapes = [\n",
    "        ([3, 100], [10]),\n",
    "        ([100], [1]),\n",
    "        ([1, 100], [10]),\n",
    "        ([784], [10]),\n",
    "        ([1, 100], [1])\n",
    "    ]\n",
    "\n",
    "test_true_labels = []\n",
    "test_predicted_labels = []\n",
    "\n",
    "for i, network in enumerate(test_networks):\n",
    "    print(f\"\\nTesting network {i+1}:\")\n",
    "    print(network)\n",
    "    generated_description = generate_description_for_network(model, tokenizer, network, device)\n",
    "    print(\"Generated description:\", generated_description)\n",
    "    pred_input, pred_output = extract_shapes(generated_description)\n",
    "    print(f\"Predicted shapes: Input {pred_input}, Output {pred_output}\")\n",
    "    print(f\"True shapes: Input {true_shapes[i][0]}, Output {true_shapes[i][1]}\")\n",
    "        \n",
    "    test_true_labels.append((str(true_shapes[i][0]), str(true_shapes[i][1])))\n",
    "    test_predicted_labels.append((pred_input, pred_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Network Performance Metrics:\n",
      "Accuracy: 0.4000\n",
      "F1 Score: 1.0000\n",
      "\n",
      "Detailed analysis of test results:\n",
      "\n",
      "Network 1:\n",
      "True: Input [3, 100], Output [10]\n",
      "Predicted: Input [3, 125, 128], Output [128, 125, 10]\n",
      "Input shape correct: False\n",
      "Output shape correct: False\n",
      "Both shapes correct: False\n",
      "\n",
      "Network 2:\n",
      "True: Input [100], Output [1]\n",
      "Predicted: Input [100], Output [1]\n",
      "Input shape correct: True\n",
      "Output shape correct: True\n",
      "Both shapes correct: True\n",
      "\n",
      "Network 3:\n",
      "True: Input [1, 100], Output [10]\n",
      "Predicted: Input [1, 62, 64], Output [64, 62, 10]\n",
      "Input shape correct: False\n",
      "Output shape correct: False\n",
      "Both shapes correct: False\n",
      "\n",
      "Network 4:\n",
      "True: Input [784], Output [10]\n",
      "Predicted: Input [784], Output [10]\n",
      "Input shape correct: True\n",
      "Output shape correct: True\n",
      "Both shapes correct: True\n",
      "\n",
      "Network 5:\n",
      "True: Input [1, 100], Output [1]\n",
      "Predicted: Input [1, 62, 64], Output [64, 62, 1]\n",
      "Input shape correct: False\n",
      "Output shape correct: False\n",
      "Both shapes correct: False\n",
      "\n",
      "Additional Analysis:\n",
      "Correct predictions: 2 out of 5\n",
      "Correct input shape predictions: 2 out of 5\n",
      "Correct output shape predictions: 2 out of 5\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for the 5 test networks\n",
    "test_metrics = calculate_metrics(test_true_labels, test_predicted_labels)\n",
    "print(\"\\nTest Network Performance Metrics:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Detailed analysis of test results\n",
    "print(\"\\nDetailed analysis of test results:\")\n",
    "for i, (true, pred) in enumerate(zip(test_true_labels, test_predicted_labels)):\n",
    "    print(f\"\\nNetwork {i+1}:\")\n",
    "    print(f\"True: Input {true[0]}, Output {true[1]}\")\n",
    "    print(f\"Predicted: Input {pred[0]}, Output {pred[1]}\")\n",
    "    print(f\"Input shape correct: {true[0] == pred[0]}\")\n",
    "    print(f\"Output shape correct: {true[1] == pred[1]}\")\n",
    "    print(f\"Both shapes correct: {true == pred}\")\n",
    "\n",
    "# Additional Analysis\n",
    "print(\"\\nAdditional Analysis:\")\n",
    "# Distribution of correct predictions\n",
    "correct_predictions = sum(t == p for t, p in zip(test_true_labels, test_predicted_labels))\n",
    "print(f\"Correct predictions: {correct_predictions} out of {len(test_true_labels)}\")\n",
    "    \n",
    "# Analysis of input shape predictions\n",
    "input_shape_correct = sum(t[0] == p[0] for t, p in zip(test_true_labels, test_predicted_labels))\n",
    "print(f\"Correct input shape predictions: {input_shape_correct} out of {len(test_true_labels)}\")\n",
    "    \n",
    "# Analysis of output shape predictions\n",
    "output_shape_correct = sum(t[1] == p[1] for t, p in zip(test_true_labels, test_predicted_labels))\n",
    "print(f\"Correct output shape predictions: {output_shape_correct} out of {len(test_true_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error Analysis:\n",
      "Network 1:\n",
      "  True: Input [3, 100], Output [10]\n",
      "  Predicted: Input [3, 125, 128], Output [128, 125, 10]\n",
      "Network 3:\n",
      "  True: Input [1, 100], Output [10]\n",
      "  Predicted: Input [1, 62, 64], Output [64, 62, 10]\n",
      "Network 5:\n",
      "  True: Input [1, 100], Output [1]\n",
      "  Predicted: Input [1, 62, 64], Output [64, 62, 1]\n",
      "\n",
      "3D Constrained Neural Network Description Generator process completed.\n"
     ]
    }
   ],
   "source": [
    "# Error analysis\n",
    "errors = [(i, t, p) for i, (t, p) in enumerate(zip(test_true_labels, test_predicted_labels)) if t != p]\n",
    "if errors:\n",
    "    print(\"\\nError Analysis:\")\n",
    "    for i, true, pred in errors:\n",
    "        print(f\"Network {i+1}:\")\n",
    "        print(f\"  True: Input {true[0]}, Output {true[1]}\")\n",
    "        print(f\"  Predicted: Input {pred[0]}, Output {pred[1]}\")\n",
    "else:\n",
    "    print(\"\\nNo errors in test set predictions.\")\n",
    "\n",
    "print(\"\\n3D Constrained Neural Network Description Generator process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
