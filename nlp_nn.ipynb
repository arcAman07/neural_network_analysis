{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (4.42.4)\n",
      "Requirement already satisfied: tqdm in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (4.66.4)\n",
      "Requirement already satisfied: sentencepiece in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: matplotlib in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: seaborn in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: pandas in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers tqdm sentencepiece matplotlib seaborn scikit-learn pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS (Apple Silicon GPU) is available. Using GPU.\n",
      "Starting the Comprehensive GPU Neural Network Description Generator...\n",
      "Generating data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data: 100%|██████████| 10000/10000 [00:00<00:00, 126797.34it/s]\n",
      "Generating data: 100%|██████████| 1000/1000 [00:00<00:00, 122989.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10000 training samples and 1000 evaluation samples.\n",
      "Data generation completed and saved.\n",
      "Analyzing and visualizing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model and datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [30:31<00:00,  2.93s/it]  \n",
      "Evaluating: 100%|██████████| 63/63 [00:14<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6179\n",
      "Eval loss: 0.0396\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 625/625 [54:28<00:00,  5.23s/it]  \n",
      "Evaluating: 100%|██████████| 63/63 [00:14<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0489\n",
      "Eval loss: 0.0282\n",
      "Training completed and model saved.\n",
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Evaluating:   0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::isin.Tensor_Tensor_out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb#W3sZmlsZQ%3D%3D?line=484'>485</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mComprehensive GPU Neural Network Description Generator process completed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb#W3sZmlsZQ%3D%3D?line=486'>487</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb#W3sZmlsZQ%3D%3D?line=487'>488</a>\u001b[0m     main()\n",
      "\u001b[1;32m/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb#W3sZmlsZQ%3D%3D?line=368'>369</a>\u001b[0m loaded_model \u001b[39m=\u001b[39m T5ForConditionalGeneration\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mneural_network_description_model\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb#W3sZmlsZQ%3D%3D?line=369'>370</a>\u001b[0m loaded_tokenizer \u001b[39m=\u001b[39m T5Tokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mneural_network_description_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb#W3sZmlsZQ%3D%3D?line=371'>372</a>\u001b[0m true_labels, predicted_labels \u001b[39m=\u001b[39m evaluate_model(loaded_model, loaded_tokenizer, eval_data, device)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb#W3sZmlsZQ%3D%3D?line=373'>374</a>\u001b[0m \u001b[39m# Calculate and display metrics\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb#W3sZmlsZQ%3D%3D?line=374'>375</a>\u001b[0m metrics \u001b[39m=\u001b[39m calculate_metrics(true_labels, predicted_labels)\n",
      "\u001b[1;32m/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb#W3sZmlsZQ%3D%3D?line=221'>222</a>\u001b[0m true_description \u001b[39m=\u001b[39m item[\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb#W3sZmlsZQ%3D%3D?line=223'>224</a>\u001b[0m input_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(input_text, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb#W3sZmlsZQ%3D%3D?line=224'>225</a>\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(input_ids, max_length\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb#W3sZmlsZQ%3D%3D?line=225'>226</a>\u001b[0m predicted_description \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mdecode(output[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/arcaman07/Documents/Projects/Kaggle/RL_scheduling/nlp_nn.ipynb#W3sZmlsZQ%3D%3D?line=227'>228</a>\u001b[0m true_input, true_output \u001b[39m=\u001b[39m extract_shapes(true_description)\n",
      "File \u001b[0;32m~/anaconda3/envs/cv2/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cv2/lib/python3.12/site-packages/transformers/generation/utils.py:1664\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1661\u001b[0m batch_size \u001b[39m=\u001b[39m inputs_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1663\u001b[0m device \u001b[39m=\u001b[39m inputs_tensor\u001b[39m.\u001b[39mdevice\n\u001b[0;32m-> 1664\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_special_tokens(generation_config, kwargs_has_attention_mask, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m   1666\u001b[0m \u001b[39m# decoder-only models must use left-padding for batched generation.\u001b[39;00m\n\u001b[1;32m   1667\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m   1668\u001b[0m     \u001b[39m# If `input_ids` was given, check if the last id in any sequence is `pad_token_id`\u001b[39;00m\n\u001b[1;32m   1669\u001b[0m     \u001b[39m# Note: If using, `inputs_embeds` this check does not work, because we want to be more hands-off.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cv2/lib/python3.12/site-packages/transformers/generation/utils.py:1513\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_special_tokens\u001b[0;34m(self, generation_config, kwargs_has_attention_mask, device)\u001b[0m\n\u001b[1;32m   1510\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSetting `pad_token_id` to `eos_token_id`:\u001b[39m\u001b[39m{\u001b[39;00mpad_token_id\u001b[39m}\u001b[39;00m\u001b[39m for open-end generation.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1512\u001b[0m \u001b[39m# we can't infer attn mask if pad token is set to be eos token in model's generation config\u001b[39;00m\n\u001b[0;32m-> 1513\u001b[0m \u001b[39mif\u001b[39;00m eos_token_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m torch\u001b[39m.\u001b[39;49misin(elements\u001b[39m=\u001b[39;49meos_token_id, test_elements\u001b[39m=\u001b[39;49mpad_token_id)\u001b[39m.\u001b[39many():\n\u001b[1;32m   1514\u001b[0m     \u001b[39mif\u001b[39;00m kwargs_has_attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs_has_attention_mask:\n\u001b[1;32m   1515\u001b[0m         logger\u001b[39m.\u001b[39mwarning_once(\n\u001b[1;32m   1516\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1517\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAs a consequence, you may observe unexpected behavior. Please pass your input\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms `attention_mask` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1518\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mto obtain reliable results.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1519\u001b[0m         )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::isin.Tensor_Tensor_out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Check for GPU availability\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS (Apple Silicon GPU) is available. Using GPU.\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA GPU is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU available. Using CPU.\")\n",
    "\n",
    "# Data Generation\n",
    "\n",
    "def generate_network():\n",
    "    layers = []\n",
    "    input_shape = [random.randint(1, 256) for _ in range(random.randint(1, 3))]\n",
    "    current_shape = input_shape.copy()\n",
    "\n",
    "    for _ in range(random.randint(1, 10)):\n",
    "        layer_type = random.choice(['Linear', 'Conv1d', 'Conv2d', 'Conv3d', 'LSTM', 'GRU'])\n",
    "        if layer_type == 'Linear':\n",
    "            in_features = current_shape[-1]\n",
    "            out_features = random.randint(1, 256)\n",
    "            layers.append(f\"nn.Linear(in_features={in_features}, out_features={out_features})\")\n",
    "            current_shape = current_shape[:-1] + [out_features]\n",
    "        elif layer_type in ['Conv1d', 'Conv2d', 'Conv3d']:\n",
    "            in_channels = current_shape[0]\n",
    "            out_channels = random.randint(1, 64)\n",
    "            kernel_size = random.randint(1, 5)\n",
    "            layers.append(f\"nn.{layer_type}(in_channels={in_channels}, out_channels={out_channels}, kernel_size={kernel_size})\")\n",
    "            current_shape[0] = out_channels\n",
    "        elif layer_type in ['LSTM', 'GRU']:\n",
    "            input_size = current_shape[-1]\n",
    "            hidden_size = random.randint(1, 128)\n",
    "            layers.append(f\"nn.{layer_type}(input_size={input_size}, hidden_size={hidden_size}, batch_first=True)\")\n",
    "            current_shape[-1] = hidden_size\n",
    "\n",
    "    return input_shape, current_shape, layers\n",
    "\n",
    "def generate_description(input_shape, output_shape):\n",
    "    return f\"This neural network takes an input of shape {input_shape} and produces an output of shape {output_shape}.\"\n",
    "\n",
    "def generate_data(num_samples, time_limit):\n",
    "    data = []\n",
    "    start_time = time.time()\n",
    "    for _ in tqdm(range(num_samples), desc=\"Generating data\"):\n",
    "        if time.time() - start_time > time_limit:\n",
    "            break\n",
    "        input_shape, output_shape, layers = generate_network()\n",
    "        network = \"nn.Sequential(\\n    \" + \",\\n    \".join(layers) + \"\\n)\"\n",
    "        description = generate_description(input_shape, output_shape)\n",
    "        data.append({\"network\": network, \"description\": description})\n",
    "    return data\n",
    "\n",
    "# Data Analysis and Visualization\n",
    "\n",
    "def analyze_data(data):\n",
    "    layer_types = []\n",
    "    input_shapes = []\n",
    "    output_shapes = []\n",
    "\n",
    "    for item in data:\n",
    "        network = item['network']\n",
    "        layer_types.extend(re.findall(r'nn\\.(\\w+)', network))\n",
    "        input_shape, output_shape = extract_shapes(item['description'])\n",
    "        input_shapes.append(eval(input_shape))\n",
    "        output_shapes.append(eval(output_shape))\n",
    "\n",
    "    return layer_types, input_shapes, output_shapes\n",
    "\n",
    "def visualize_data(layer_types, input_shapes, output_shapes):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.countplot(y=layer_types)\n",
    "    plt.title('Distribution of Layer Types')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('layer_types_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "    input_dims = [len(shape) for shape in input_shapes]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(input_dims, bins=range(1, max(input_dims)+2), kde=True)\n",
    "    plt.title('Distribution of Input Shape Dimensions')\n",
    "    plt.xlabel('Number of Dimensions')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('input_shape_dimensions.png')\n",
    "    plt.close()\n",
    "\n",
    "    output_dims = [len(shape) for shape in output_shapes]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(output_dims, bins=range(1, max(output_dims)+2), kde=True)\n",
    "    plt.title('Distribution of Output Shape Dimensions')\n",
    "    plt.xlabel('Number of Dimensions')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output_shape_dimensions.png')\n",
    "    plt.close()\n",
    "\n",
    "    input_sizes = [np.prod(shape) for shape in input_shapes]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(input_sizes, bins=30, kde=True)\n",
    "    plt.title('Distribution of Input Sizes')\n",
    "    plt.xlabel('Input Size (Total Number of Elements)')\n",
    "    plt.xscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('input_sizes_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "    output_sizes = [np.prod(shape) for shape in output_shapes]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(output_sizes, bins=30, kde=True)\n",
    "    plt.title('Distribution of Output Sizes')\n",
    "    plt.xlabel('Output Size (Total Number of Elements)')\n",
    "    plt.xscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output_sizes_distribution.png')\n",
    "    plt.close()\n",
    "\n",
    "# Model and Dataset\n",
    "\n",
    "class NeuralNetworkDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        input_encoding = self.tokenizer.encode_plus(\n",
    "            item['network'],\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        target_encoding = self.tokenizer.encode_plus(\n",
    "            item['description'],\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_encoding['input_ids'].flatten(),\n",
    "            'attention_mask': input_encoding['attention_mask'].flatten(),\n",
    "            'labels': target_encoding['input_ids'].flatten()\n",
    "        }\n",
    "\n",
    "# Training and Evaluation\n",
    "\n",
    "def train(model, train_dataloader, optimizer, device, max_time):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "        if time.time() - start_time > max_time:\n",
    "            break\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(train_dataloader)\n",
    "\n",
    "def evaluate(model, eval_dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(eval_dataloader)\n",
    "\n",
    "def generate_description_for_network(model, tokenizer, network_str, device):\n",
    "    input_ids = tokenizer.encode(network_str, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(input_ids, max_length=100)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "def extract_shapes(description):\n",
    "    shapes = re.findall(r'\\[.*?\\]', description)\n",
    "    return shapes[0] if shapes else None, shapes[-1] if shapes else None\n",
    "\n",
    "def evaluate_model(model, tokenizer, test_data, device):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(test_data, desc=\"Evaluating\"):\n",
    "            input_text = item['network']\n",
    "            true_description = item['description']\n",
    "            \n",
    "            input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "            output = model.generate(input_ids, max_length=100)\n",
    "            predicted_description = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "            \n",
    "            true_input, true_output = extract_shapes(true_description)\n",
    "            pred_input, pred_output = extract_shapes(predicted_description)\n",
    "            \n",
    "            true_labels.append((true_input, true_output))\n",
    "            predicted_labels.append((pred_input, pred_output))\n",
    "\n",
    "    return true_labels, predicted_labels\n",
    "\n",
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    correct_input = sum(t[0] == p[0] for t, p in zip(true_labels, predicted_labels))\n",
    "    correct_output = sum(t[1] == p[1] for t, p in zip(true_labels, predicted_labels))\n",
    "    correct_both = sum(t == p for t, p in zip(true_labels, predicted_labels))\n",
    "    \n",
    "    total = len(true_labels)\n",
    "    \n",
    "    accuracy_input = correct_input / total\n",
    "    accuracy_output = correct_output / total\n",
    "    accuracy_both = correct_both / total\n",
    "    \n",
    "    precision = correct_both / total\n",
    "    recall = correct_both / total\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'Accuracy (Input Shape)': accuracy_input,\n",
    "        'Accuracy (Output Shape)': accuracy_output,\n",
    "        'Accuracy (Both Shapes)': accuracy_both,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1_score\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predicted_labels):\n",
    "    true_simplified = ['Correct' if t[0] == p[0] and t[1] == p[1] else 'Incorrect' for t, p in zip(true_labels, predicted_labels)]\n",
    "    pred_simplified = ['Correct' if t[0] == p[0] and t[1] == p[1] else 'Incorrect' for t, p in zip(true_labels, predicted_labels)]\n",
    "    \n",
    "    cm = confusion_matrix(true_simplified, pred_simplified, labels=['Correct', 'Incorrect'])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Correct', 'Incorrect'], yticklabels=['Correct', 'Incorrect'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "def analyze_test_results(true_labels, predicted_labels):\n",
    "    correct_predictions = [t == p for t, p in zip(true_labels, predicted_labels)]\n",
    "    incorrect_predictions = [t != p for t, p in zip(true_labels, predicted_labels)]\n",
    "    \n",
    "    correct_samples = [t for t, c in zip(true_labels, correct_predictions) if c]\n",
    "    incorrect_samples = [t for t, c in zip(true_labels, incorrect_predictions) if c]\n",
    "    \n",
    "    print(\"\\nTest Data Analysis:\")\n",
    "    print(f\"Total samples: {len(true_labels)}\")\n",
    "    print(f\"Correct predictions: {sum(correct_predictions)}\")\n",
    "    print(f\"Incorrect predictions: {sum(incorrect_predictions)}\")\n",
    "    \n",
    "    print(\"\\nMost common correct predictions:\")\n",
    "    print(Counter(correct_samples).most_common(5))\n",
    "    \n",
    "    print(\"\\nMost common incorrect predictions:\")\n",
    "    print(Counter(incorrect_samples).most_common(5))\n",
    "\n",
    "def error_analysis(true_labels, predicted_labels):\n",
    "    errors = [(t, p) for t, p in zip(true_labels, predicted_labels) if t != p]\n",
    "    \n",
    "    print(\"\\nError Analysis:\")\n",
    "    print(f\"Total errors: {len(errors)}\")\n",
    "    \n",
    "    input_shape_errors = sum(t[0] != p[0] for t, p in errors)\n",
    "    output_shape_errors = sum(t[1] != p[1] for t, p in errors)\n",
    "    \n",
    "    print(f\"Input shape errors: {input_shape_errors}\")\n",
    "    print(f\"Output shape errors: {output_shape_errors}\")\n",
    "    \n",
    "    print(\"\\nSample of errors:\")\n",
    "    for true, pred in errors[:5]:\n",
    "        print(f\"True: {true}, Predicted: {pred}\")\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    print(\"Starting the Comprehensive GPU Neural Network Description Generator...\")\n",
    "    \n",
    "    # Data Generation\n",
    "    print(\"Generating data...\")\n",
    "    train_data = generate_data(10000, 7200)  # 2 hours for training data\n",
    "    eval_data = generate_data(1000, 600)  # 10 minutes for eval data\n",
    "\n",
    "    print(f\"Generated {len(train_data)} training samples and {len(eval_data)} evaluation samples.\")\n",
    "\n",
    "    # Save data to files\n",
    "    with open('train_data.json', 'w') as f:\n",
    "        json.dump(train_data, f)\n",
    "    with open('eval_data.json', 'w') as f:\n",
    "        json.dump(eval_data, f)\n",
    "\n",
    "    print(\"Data generation completed and saved.\")\n",
    "\n",
    "    # Data Analysis and Visualization\n",
    "    print(\"Analyzing and visualizing data...\")\n",
    "    layer_types, input_shapes, output_shapes = analyze_data(train_data)\n",
    "    visualize_data(layer_types, input_shapes, output_shapes)\n",
    "\n",
    "    # Model Training\n",
    "    print(\"Preparing model and datasets...\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "    train_dataset = NeuralNetworkDataset(train_data, tokenizer, max_length=256)\n",
    "    eval_dataset = NeuralNetworkDataset(eval_data, tokenizer, max_length=256)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    eval_dataloader = DataLoader(eval_dataset, batch_size=16)\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "    num_epochs = 2\n",
    "    max_train_time = 7200  # 2 hours\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        train_loss = train(model, train_dataloader, optimizer, device, max_train_time - (time.time() - start_time))\n",
    "        eval_loss = evaluate(model, eval_dataloader, device)\n",
    "        print(f\"Train loss: {train_loss:.4f}\")\n",
    "        print(f\"Eval loss: {eval_loss:.4f}\")\n",
    "        \n",
    "        if time.time() - start_time > max_train_time:\n",
    "            print(\"Training time limit reached. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    # Save the model\n",
    "    model.save_pretrained(\"neural_network_description_model\")\n",
    "    tokenizer.save_pretrained(\"neural_network_description_model\")\n",
    "\n",
    "    print(\"Training completed and model saved.\")\n",
    "\n",
    "    # Model Evaluation\n",
    "    print(\"Evaluating the model...\")\n",
    "    loaded_model = T5ForConditionalGeneration.from_pretrained(\"neural_network_description_model\").to(device)\n",
    "    loaded_tokenizer = T5Tokenizer.from_pretrained(\"neural_network_description_model\")\n",
    "\n",
    "    true_labels, predicted_labels = evaluate_model(loaded_model, loaded_tokenizer, eval_data, device)\n",
    "\n",
    "    # Calculate and display metrics\n",
    "    metrics = calculate_metrics(true_labels, predicted_labels)\n",
    "    print(\"\\nModel Performance Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Test Data Analysis\n",
    "    analyze_test_results(true_labels, predicted_labels)\n",
    "\n",
    "    # Error Analysis\n",
    "    error_analysis(true_labels, predicted_labels)\n",
    "\n",
    "    # Evaluation on 5 different unique neural network architectures\n",
    "    print(\"\\nEvaluating on 5 different unique neural network architectures...\")\n",
    "    \n",
    "    test_networks = [\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=32768, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=10)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.LSTM(input_size=100, hidden_size=256, num_layers=2, batch_first=True),\n",
    "            nn.Linear(in_features=256, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=1)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=3136, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=10)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Linear(in_features=784, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features=256, out_features=10)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Conv3d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=8192, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=1)\n",
    "        )\"\"\"\n",
    "    ]\n",
    "\n",
    "    true_shapes = [\n",
    "        ([3, 224, 224], [10]),\n",
    "        ([32, 100], [1]),\n",
    "        ([1, 500], [10]),\n",
    "        ([784], [10]),\n",
    "        ([1, 32, 32, 32], [1])\n",
    "    ]\n",
    "\n",
    "    test_true_labels = []\n",
    "    test_predicted_labels = []\n",
    "\n",
    "    for i, network in enumerate(test_networks):\n",
    "        print(f\"\\nTesting network {i+1}:\")\n",
    "        print(network)\n",
    "        generated_description = generate_description_for_network(loaded_model, loaded_tokenizer, network, device)\n",
    "        print(\"Generated description:\", generated_description)\n",
    "        pred_input, pred_output = extract_shapes(generated_description)\n",
    "        print(f\"Predicted shapes: Input {pred_input}, Output {pred_output}\")\n",
    "        print(f\"True shapes: Input {true_shapes[i][0]}, Output {true_shapes[i][1]}\")\n",
    "        \n",
    "        test_true_labels.append((str(true_shapes[i][0]), str(true_shapes[i][1])))\n",
    "        test_predicted_labels.append((pred_input, pred_output))\n",
    "\n",
    "    # Calculate metrics for the 5 test networks\n",
    "    test_metrics = calculate_metrics(test_true_labels, test_predicted_labels)\n",
    "    print(\"\\nTest Network Performance Metrics:\")\n",
    "    for metric, value in test_metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    # Detailed analysis of test results\n",
    "    print(\"\\nDetailed analysis of test results:\")\n",
    "    for i, (true, pred) in enumerate(zip(test_true_labels, test_predicted_labels)):\n",
    "        print(f\"\\nNetwork {i+1}:\")\n",
    "        print(f\"True: Input {true[0]}, Output {true[1]}\")\n",
    "        print(f\"Predicted: Input {pred[0]}, Output {pred[1]}\")\n",
    "        print(f\"Input shape correct: {true[0] == pred[0]}\")\n",
    "        print(f\"Output shape correct: {true[1] == pred[1]}\")\n",
    "        print(f\"Both shapes correct: {true == pred}\")\n",
    "\n",
    "    print(\"\\nComprehensive GPU Neural Network Description Generator process completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (0.18.1)\n",
      "Requirement already satisfied: torchaudio in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/arcaman07/anaconda3/envs/cv2/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "!pip install --upgrade torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data: 100%|██████████| 1000/1000 [00:00<00:00, 73626.91it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_data = generate_data(1000, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Evaluating: 100%|██████████| 1000/1000 [10:48<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Evaluating the model...\")\n",
    "loaded_model = T5ForConditionalGeneration.from_pretrained(\"neural_network_description_model\").to(device)\n",
    "loaded_tokenizer = T5Tokenizer.from_pretrained(\"neural_network_description_model\")\n",
    "\n",
    "true_labels, predicted_labels = evaluate_model(loaded_model, loaded_tokenizer, eval_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Metrics:\n",
      "Accuracy (Input Shape): 0.3080\n",
      "Accuracy (Output Shape): 0.2910\n",
      "Accuracy (Both Shapes): 0.2720\n",
      "Precision: 0.2720\n",
      "Recall: 0.2720\n",
      "F1 Score: 0.2720\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display metrics\n",
    "metrics = calculate_metrics(true_labels, predicted_labels)\n",
    "print(\"\\nModel Performance Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Data Analysis:\n",
      "Total samples: 1000\n",
      "Correct predictions: 272\n",
      "Incorrect predictions: 728\n",
      "\n",
      "Most common correct predictions:\n",
      "[(('[138]', '[17]'), 1), (('[172, 66]', '[41, 69]'), 1), (('[10, 243]', '[57, 71]'), 1), (('[37, 47]', '[42, 114]'), 1), (('[252, 91]', '[24, 96]'), 1)]\n",
      "\n",
      "Most common incorrect predictions:\n",
      "[(('[80]', '[37]'), 2), (('[161, 30, 79]', '[12, 30, 130]'), 1), (('[251]', '[85]'), 1), (('[20, 41, 84]', '[1, 41, 9]'), 1), (('[78, 198, 80]', '[22, 198, 78]'), 1)]\n"
     ]
    }
   ],
   "source": [
    "# Test Data Analysis\n",
    "analyze_test_results(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error Analysis:\n",
      "Total errors: 728\n",
      "Input shape errors: 692\n",
      "Output shape errors: 709\n",
      "\n",
      "Sample of errors:\n",
      "True: ('[161, 30, 79]', '[12, 30, 130]'), Predicted: ('[161, 79]', '[12, 130]')\n",
      "True: ('[251]', '[85]'), Predicted: ('[251, 251]', '[85, 85]')\n",
      "True: ('[20, 41, 84]', '[1, 41, 9]'), Predicted: ('[20, 84]', '[1, 9]')\n",
      "True: ('[78, 198, 80]', '[22, 198, 78]'), Predicted: ('[78, 80]', '[22, 78]')\n",
      "True: ('[224]', '[230]'), Predicted: ('[224, 230]', '[3, 230]')\n"
     ]
    }
   ],
   "source": [
    "# Error Analysis\n",
    "error_analysis(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_networks = [\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=32768, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=10)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.LSTM(input_size=100, hidden_size=256, num_layers=2, batch_first=True),\n",
    "            nn.Linear(in_features=256, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=1)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=3136, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=10)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Linear(in_features=784, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features=256, out_features=10)\n",
    "        )\"\"\",\n",
    "        \"\"\"nn.Sequential(\n",
    "            nn.Conv3d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=8192, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=1)\n",
    "        )\"\"\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing network 1:\n",
      "nn.Sequential(\n",
      "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
      "            nn.ReLU(),\n",
      "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
      "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
      "            nn.ReLU(),\n",
      "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
      "            nn.Flatten(),\n",
      "            nn.Linear(in_features=32768, out_features=512),\n",
      "            nn.ReLU(),\n",
      "            nn.Linear(in_features=512, out_features=10)\n",
      "        )\n",
      "Generated description: This neural network takes an input of shape [32768, 328, 328, 328, 328, 328, 328, 512] and produces an output of shape [128, 512].\n",
      "Predicted shapes: Input [32768, 328, 328, 328, 328, 328, 328, 512], Output [128, 512]\n",
      "True shapes: Input [3, 224, 224], Output [10]\n",
      "\n",
      "Testing network 2:\n",
      "nn.Sequential(\n",
      "            nn.LSTM(input_size=100, hidden_size=256, num_layers=2, batch_first=True),\n",
      "            nn.Linear(in_features=256, out_features=64),\n",
      "            nn.ReLU(),\n",
      "            nn.Linear(in_features=64, out_features=1)\n",
      "        )\n",
      "Generated description: This neural network takes an input of shape [100] and produces an output of shape [1].\n",
      "Predicted shapes: Input [100], Output [1]\n",
      "True shapes: Input [32, 100], Output [1]\n",
      "\n",
      "Testing network 3:\n",
      "nn.Sequential(\n",
      "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5),\n",
      "            nn.ReLU(),\n",
      "            nn.MaxPool1d(kernel_size=2),\n",
      "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5),\n",
      "            nn.ReLU(),\n",
      "            nn.MaxPool1d(kernel_size=2),\n",
      "            nn.Flatten(),\n",
      "            nn.Linear(in_features=3136, out_features=128),\n",
      "            nn.ReLU(),\n",
      "            nn.Linear(in_features=128, out_features=10)\n",
      "        )\n",
      "Generated description: This neural network takes an input of shape [1, 3136] and produces an output of shape [64, 10].\n",
      "Predicted shapes: Input [1, 3136], Output [64, 10]\n",
      "True shapes: Input [1, 500], Output [10]\n",
      "\n",
      "Testing network 4:\n",
      "nn.Sequential(\n",
      "            nn.Linear(in_features=784, out_features=512),\n",
      "            nn.ReLU(),\n",
      "            nn.Dropout(0.5),\n",
      "            nn.Linear(in_features=512, out_features=256),\n",
      "            nn.ReLU(),\n",
      "            nn.Dropout(0.3),\n",
      "            nn.Linear(in_features=256, out_features=10)\n",
      "        )\n",
      "Generated description: This neural network takes an input of shape [784, 784] and produces an output of shape [10, 108].\n",
      "Predicted shapes: Input [784, 784], Output [10, 108]\n",
      "True shapes: Input [784], Output [10]\n",
      "\n",
      "Testing network 5:\n",
      "nn.Sequential(\n",
      "            nn.Conv3d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
      "            nn.ReLU(),\n",
      "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
      "            nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
      "            nn.ReLU(),\n",
      "            nn.MaxPool3d(kernel_size=2, stride=2),\n",
      "            nn.Flatten(),\n",
      "            nn.Linear(in_features=8192, out_features=512),\n",
      "            nn.ReLU(),\n",
      "            nn.Linear(in_features=512, out_features=1)\n",
      "        )\n",
      "Generated description: This neural network takes an input of shape [1, 8192] and produces an output of shape [64, 512].\n",
      "Predicted shapes: Input [1, 8192], Output [64, 512]\n",
      "True shapes: Input [1, 32, 32, 32], Output [1]\n"
     ]
    }
   ],
   "source": [
    "true_shapes = [\n",
    "        ([3, 224, 224], [10]),\n",
    "        ([32, 100], [1]),\n",
    "        ([1, 500], [10]),\n",
    "        ([784], [10]),\n",
    "        ([1, 32, 32, 32], [1])\n",
    "    ]\n",
    "\n",
    "test_true_labels = []\n",
    "test_predicted_labels = []\n",
    "\n",
    "for i, network in enumerate(test_networks):\n",
    "    print(f\"\\nTesting network {i+1}:\")\n",
    "    print(network)\n",
    "    generated_description = generate_description_for_network(loaded_model, loaded_tokenizer, network, device)\n",
    "    print(\"Generated description:\", generated_description)\n",
    "    pred_input, pred_output = extract_shapes(generated_description)\n",
    "    print(f\"Predicted shapes: Input {pred_input}, Output {pred_output}\")\n",
    "    print(f\"True shapes: Input {true_shapes[i][0]}, Output {true_shapes[i][1]}\")\n",
    "        \n",
    "    test_true_labels.append((str(true_shapes[i][0]), str(true_shapes[i][1])))\n",
    "    test_predicted_labels.append((pred_input, pred_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Network Performance Metrics:\n",
      "Accuracy (Input Shape): 0.0000\n",
      "Accuracy (Output Shape): 0.2000\n",
      "Accuracy (Both Shapes): 0.0000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics for the 5 test networks\n",
    "test_metrics = calculate_metrics(test_true_labels, test_predicted_labels)\n",
    "print(\"\\nTest Network Performance Metrics:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed analysis of test results:\n",
      "\n",
      "Network 1:\n",
      "True: Input [3, 224, 224], Output [10]\n",
      "Predicted: Input [32768, 328, 328, 328, 328, 328, 328, 512], Output [128, 512]\n",
      "Input shape correct: False\n",
      "Output shape correct: False\n",
      "Both shapes correct: False\n",
      "\n",
      "Network 2:\n",
      "True: Input [32, 100], Output [1]\n",
      "Predicted: Input [100], Output [1]\n",
      "Input shape correct: False\n",
      "Output shape correct: True\n",
      "Both shapes correct: False\n",
      "\n",
      "Network 3:\n",
      "True: Input [1, 500], Output [10]\n",
      "Predicted: Input [1, 3136], Output [64, 10]\n",
      "Input shape correct: False\n",
      "Output shape correct: False\n",
      "Both shapes correct: False\n",
      "\n",
      "Network 4:\n",
      "True: Input [784], Output [10]\n",
      "Predicted: Input [784, 784], Output [10, 108]\n",
      "Input shape correct: False\n",
      "Output shape correct: False\n",
      "Both shapes correct: False\n",
      "\n",
      "Network 5:\n",
      "True: Input [1, 32, 32, 32], Output [1]\n",
      "Predicted: Input [1, 8192], Output [64, 512]\n",
      "Input shape correct: False\n",
      "Output shape correct: False\n",
      "Both shapes correct: False\n",
      "\n",
      "Comprehensive GPU Neural Network Description Generator process completed.\n"
     ]
    }
   ],
   "source": [
    "# Detailed analysis of test results\n",
    "print(\"\\nDetailed analysis of test results:\")\n",
    "for i, (true, pred) in enumerate(zip(test_true_labels, test_predicted_labels)):\n",
    "    print(f\"\\nNetwork {i+1}:\")\n",
    "    print(f\"True: Input {true[0]}, Output {true[1]}\")\n",
    "    print(f\"Predicted: Input {pred[0]}, Output {pred[1]}\")\n",
    "    print(f\"Input shape correct: {true[0] == pred[0]}\")\n",
    "    print(f\"Output shape correct: {true[1] == pred[1]}\")\n",
    "    print(f\"Both shapes correct: {true == pred}\")\n",
    "\n",
    "print(\"\\nComprehensive GPU Neural Network Description Generator process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
